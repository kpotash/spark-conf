# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# ================ Application Properties
spark.master                     spark://troika:7077
spark.driver.memory              256m
spark.executor.memory            128m

spark.serializer                 org.apache.spark.serializer.KryoSerializer
# ========================================
# make sure to register classes in application to avoid class name overhead
# val conf = new SparkConf().setMaster(...).setAppName(...)
# conf.registerKryoClasses(Seq(classOf[MyClass1], classOf[MyClass2]))
# val sc = new SparkContext(conf)
# ========================================

#spark.kryo.classesToRegister     MyClass

spark.local.dir	                 /tmp
spark.logConf	                 true

# ================ Runtime Environment
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

# ================ Shuffle Behavior
spark.shuffle.consolidateFiles	                       false
spark.shuffle.spill	                               true
spark.shuffle.spill.compress	                       true
spark.shuffle.memoryFraction	                       0.2
spark.shuffle.compress	                               true
spark.shuffle.file.buffer.kb	                       32
spark.reducer.maxMbInFlight	                       48
spark.shuffle.manager	                               sort
spark.shuffle.sort.bypassMergeThreshold	               200
spark.shuffle.blockTransferService	               netty

# ================ Spark UI
spark.eventLog.enabled           true
spark.eventLog.dir               /home/ovik/logs

# ================ Compression and Serialization
spark.broadcast.compress	 true
spark.rdd.compress	         false
spark.io.compression.codec	 snappy

# ================ Execution Behavior
#spark.default.parallelism	
#spark.broadcast.factory	        "org.apache.spark.broadcast.TorrentBroadcastFactory"
spark.broadcast.blockSize	4096
spark.files.overwrite	        false
spark.files.fetchTimeout	60
spark.storage.memoryFraction	0.6
spark.storage.unrollFraction	0.2
#spark.tachyonStore.baseDir	System.getProperty("java.io.tmpdir")
#spark.storage.memoryMapThreshold	8192
#spark.tachyonStore.url	tachyon://localhost:19998

# ================ Scheduling
spark.task.cpus                 1
spark.task.maxFailures	        4
spark.scheduler.mode	        FIFO
spark.cores.max	                2
